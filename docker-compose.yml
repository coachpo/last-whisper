services:
  # Caddy reverse proxy
  caddy:
    image: caddy:2-alpine
    container_name: last-whisper-caddy
    ports:
      - "8008:8008"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
      - caddy_logs:/var/log/caddy
    depends_on:
      - frontend
      - backend
    restart: unless-stopped

  # Backend API service
  backend:
    build:
      context: ./last-whisper-backend
      dockerfile: Dockerfile
    container_name: last-whisper-backend
    expose:
      - "8000"
    environment:
      - ENVIRONMENT=production
      - TTS_PROVIDER=local
      - LOG_LEVEL=info
      - CORS_ORIGINS=https://lw.687786.xyz
      - HF_HOME=/app/.cache/huggingface
      - TTS_PROVIDER=google
      - GOOGLE_APPLICATION_CREDENTIALS=/app/keys/google-credentials.json
    volumes:
      # Persist audio files (use named volume for better reliability)
      - audio_data:/app/audio
      # Persist database (use named volume for better reliability)
      - database_data:/app/data
      # Mount credentials if needed
      - ./keys:/app/keys:ro
      # Cache directory for models
      - huggingface_cache:/app/.cache/huggingface
    restart: unless-stopped

  # Frontend service
  frontend:
    build:
      context: ./last-whisper-frontend
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=https://lw.687786.xyz/apis
    container_name: last-whisper-frontend
    expose:
      - "3000"
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped

# Named volumes for persistent data
volumes:
  huggingface_cache:
    driver: local
  database_data:
    driver: local
  audio_data:
    driver: local
  caddy_data:
    driver: local
  caddy_config:
    driver: local
  caddy_logs:
    driver: local
